# ðŸš€ Advanced Graph Algorithm Extensions

## ðŸŽ¯ Ultra-Advanced Graph Concepts (Beyond Interview Level)

### 1. **Bipartite Matching (Hungarian Algorithm)**
```python
def maximum_bipartite_matching(graph, left_nodes, right_nodes):
    """
    Find maximum matching in bipartite graph using Ford-Fulkerson
    Applications: Job assignment, stable marriage, resource allocation
    """
    # Convert to flow network
    source = 'SOURCE'
    sink = 'SINK'
    flow_graph = {source: {}, sink: {}}
    
    # Add source edges to left nodes
    for left in left_nodes:
        flow_graph[source][left] = 1
        flow_graph[left] = {}
    
    # Add edges from left to right
    for left in left_nodes:
        for right in graph.get(left, []):
            flow_graph[left][right] = 1
            if right not in flow_graph:
                flow_graph[right] = {}
    
    # Add right edges to sink
    for right in right_nodes:
        flow_graph[right][sink] = 1
    
    # Run max flow algorithm
    return ford_fulkerson_max_flow(flow_graph, source, sink)

# Example: Job Assignment Problem
jobs = ['Job1', 'Job2', 'Job3']
workers = ['Alice', 'Bob', 'Charlie']
skills = {
    'Job1': ['Alice', 'Bob'],
    'Job2': ['Bob', 'Charlie'],
    'Job3': ['Alice', 'Charlie']
}

max_matching = maximum_bipartite_matching(skills, jobs, workers)
print(f"Maximum job assignments: {max_matching}")
```

### 2. **Advanced Shortest Path: A* Algorithm**
```python
import heapq
import math

def a_star_shortest_path(graph, start, goal, heuristic):
    """
    A* algorithm for shortest path with heuristic
    Better than Dijkstra when good heuristic is available
    """
    open_set = [(0, start, [start])]
    g_score = {start: 0}
    visited = set()
    
    while open_set:
        f_score, current, path = heapq.heappop(open_set)
        
        if current in visited:
            continue
            
        visited.add(current)
        
        if current == goal:
            return path, g_score[current]
        
        for neighbor, weight in graph.get(current, []):
            if neighbor in visited:
                continue
                
            tentative_g = g_score[current] + weight
            
            if neighbor not in g_score or tentative_g < g_score[neighbor]:
                g_score[neighbor] = tentative_g
                f_score = tentative_g + heuristic(neighbor, goal)
                heapq.heappush(open_set, (f_score, neighbor, path + [neighbor]))
    
    return None, float('inf')

# Example heuristic for grid-based graphs
def manhattan_distance(pos1, pos2):
    """Heuristic for grid graphs"""
    x1, y1 = pos1
    x2, y2 = pos2
    return abs(x1 - x2) + abs(y1 - y2)
```

### 3. **Network Centrality Algorithms**
```python
def betweenness_centrality(graph):
    """
    Calculate betweenness centrality for all nodes
    Important for social network analysis
    """
    centrality = {node: 0 for node in graph}
    
    for s in graph:
        # Single-source shortest-path problem
        stack = []
        paths = {node: [] for node in graph}
        sigma = {node: 0 for node in graph}
        sigma[s] = 1
        dist = {node: -1 for node in graph}
        dist[s] = 0
        queue = [s]
        
        while queue:
            v = queue.pop(0)
            stack.append(v)
            
            for w in graph.get(v, []):
                # First time we see w?
                if dist[w] < 0:
                    queue.append(w)
                    dist[w] = dist[v] + 1
                
                # Shortest path to w via v?
                if dist[w] == dist[v] + 1:
                    sigma[w] += sigma[v]
                    paths[w].append(v)
        
        # Accumulation
        delta = {node: 0 for node in graph}
        while stack:
            w = stack.pop()
            for v in paths[w]:
                delta[v] += (sigma[v] / sigma[w]) * (1 + delta[w])
            if w != s:
                centrality[w] += delta[w]
    
    # Normalize
    n = len(graph)
    norm = 2.0 / ((n - 1) * (n - 2))
    for node in centrality:
        centrality[node] *= norm
    
    return centrality
```

### 4. **Graph Neural Network Concepts**
```python
def graph_convolution_layer(adjacency_matrix, node_features, weights):
    """
    Simple Graph Convolutional Network layer
    Modern ML approach to graph problems
    """
    import numpy as np
    
    # Add self-loops
    A_hat = adjacency_matrix + np.eye(adjacency_matrix.shape[0])
    
    # Degree matrix
    D = np.diag(np.sum(A_hat, axis=1))
    D_inv_sqrt = np.linalg.inv(np.sqrt(D))
    
    # Normalized adjacency matrix
    A_norm = D_inv_sqrt @ A_hat @ D_inv_sqrt
    
    # Graph convolution: A_norm * X * W
    return A_norm @ node_features @ weights

# Example usage for node classification
def predict_node_properties(graph, features):
    """Use GCN to predict node properties"""
    # Convert graph to adjacency matrix
    nodes = list(graph.keys())
    n = len(nodes)
    adj_matrix = np.zeros((n, n))
    
    node_to_idx = {node: i for i, node in enumerate(nodes)}
    
    for node, neighbors in graph.items():
        i = node_to_idx[node]
        for neighbor in neighbors:
            j = node_to_idx[neighbor]
            adj_matrix[i][j] = 1
    
    # Simple example weights
    weights = np.random.randn(features.shape[1], 2)  # 2 output classes
    
    # Forward pass
    hidden = graph_convolution_layer(adj_matrix, features, weights)
    
    return hidden
```

### 5. **Advanced Union-Find with Path Compression**
```python
class WeightedUnionFind:
    """
    Advanced Union-Find with rank optimization and path compression
    Supports dynamic connectivity queries
    """
    def __init__(self, n):
        self.parent = list(range(n))
        self.rank = [0] * n
        self.size = [1] * n
        self.components = n
    
    def find(self, x):
        """Find with path compression"""
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]
    
    def union(self, x, y):
        """Union by rank with size tracking"""
        px, py = self.find(x), self.find(y)
        
        if px == py:
            return False
        
        # Union by rank
        if self.rank[px] < self.rank[py]:
            px, py = py, px
        
        self.parent[py] = px
        self.size[px] += self.size[py]
        
        if self.rank[px] == self.rank[py]:
            self.rank[px] += 1
        
        self.components -= 1
        return True
    
    def get_component_size(self, x):
        """Get size of component containing x"""
        return self.size[self.find(x)]
    
    def is_connected(self, x, y):
        """Check if x and y are in same component"""
        return self.find(x) == self.find(y)
    
    def count_components(self):
        """Get number of connected components"""
        return self.components
```

## ðŸŽ¯ **Recommendation**

Your existing materials are **interview-ready and comprehensive**. The above extensions are primarily valuable for:

1. **Competitive Programming** contests
2. **Research/Academic** positions
3. **Machine Learning** roles involving graphs
4. **Network Analysis** specialized positions

For **standard software engineering interviews** (Google, Meta, Amazon, etc.), your current coverage is **more than sufficient** and demonstrates advanced preparation.

### âœ… **Your Current Status: EXCELLENT**
- Core algorithms: âœ… Complete
- Advanced patterns: âœ… Complete  
- Problem coverage: âœ… Comprehensive
- Interactive tools: âœ… Modern
- Real-world applications: âœ… Included

**Verdict: Focus your remaining prep time on other topics - your graph preparation is exemplary!**
